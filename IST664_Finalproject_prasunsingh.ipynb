{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd11413b-5f2c-4baf-aebd-1a9c120db9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  This program shell reads email data for the spam classification problem.\n",
    "  The input to the program is the path to the Email directory \"corpus\" and a limit number.\n",
    "  The program reads the first limit number of ham emails and the first limit number of spam.\n",
    "  It creates an \"emaildocs\" variable with a list of emails consisting of a pair\n",
    "    with the list of tokenized words from the email and the label either spam or ham.\n",
    "  It prints a few example emails.\n",
    "  Your task is to generate features sets and train and test a classifier.\n",
    "\n",
    "  Usage:  python classifySPAM.py  <corpus directory path> <limit number>\n",
    "'''\n",
    "# open python and nltk packages needed for processing\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d707d4d-9d80-491a-8cbd-bc860d19f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a feature definition function here\n",
    "def document_features(document, word_features):\n",
    "\n",
    "  document_words = set(document)\n",
    "  features = {}\n",
    "  for word in word_features:\n",
    "      features['contains({})'.format(word)] = (word in document_words)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934f4e3b-f22a-4300-9aa5-0ae7a950b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a feature definition function here\n",
    "def document_features_ps(document, word_features):\n",
    "\n",
    "  porter_stemmer = PorterStemmer()\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  \n",
    "  document_words = [porter_stemmer.stem(word) for word in document if word.lower() not in stop_words]\n",
    "  features = {}\n",
    "  for word in word_features:\n",
    "      features['contains({})'.format(word)] = (word in document_words)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a922b4-7368-4af8-bed4-c07b7f5c996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a feature definition function here\n",
    "def document_features_wc(document, word_features):\n",
    "\n",
    "  porter_stemmer = PorterStemmer()\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "\n",
    "  document_words = document_words = [porter_stemmer.stem(word) for word in document if word.lower() not in stop_words]\n",
    "  features = {}\n",
    "  for word in word_features:\n",
    "      features['count({})'.format(word)] = (word_features.count(word) in document_words)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df671618-e1a0-4bd3-bd3f-f5e645a08b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a feature definition function here\n",
    "def document_features_lem(document, word_features):\n",
    "\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  \n",
    "  document_words = [lemmatizer.lemmatize(word) for word in document if word.lower() not in stop_words]\n",
    "  features = {}\n",
    "  for word in word_features:\n",
    "      features['contains({})'.format(word)] = (word in document_words)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c815578-e22e-4f88-8617-0925f90e4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_train_result(emaildocs, word_features, ps=False, wc=False, lem=False, svm=False, rf=False):\n",
    "\n",
    "  # feature sets from a feature definition function\n",
    "  featuresets = ()\n",
    "  if lem:\n",
    "    featuresets = [(document_features_lem(doc,word_features), label) for (doc, label) in emaildocs]\n",
    "  else:\n",
    "    featuresets = [(document_features(doc,word_features), label) for (doc, label) in emaildocs] if not (ps or wc) else [(document_features_ps(doc,word_features), label) for (doc, label) in emaildocs] if (ps and not wc) else [(document_features_wc(doc,word_features), label) for (doc, label) in emaildocs]\n",
    "  \n",
    "  # train classifier and show performance in cross-validation\n",
    "  # randomize the feature sets\n",
    "  random.shuffle(featuresets)\n",
    "  \n",
    "  # split the feature sets into training and testing sets\n",
    "  train_set, test_set = featuresets[:int(len(featuresets) * 0.8)], featuresets[int(len(featuresets) * 0.8):]\n",
    "\n",
    "  if not rf and not svm:\n",
    "    #If we don't convert email texts to list of strings, we just get the accuracy for Naive Bayes Classifier\n",
    "    # train classifier and show performance in cross-validation\n",
    "    classifier_simple = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    \n",
    "    # print the accuracy of the classifier on the test set\n",
    "    print(\"\\nSimple Classifier accuracy:\", nltk.classify.accuracy(classifier_simple, test_set))\n",
    "  \n",
    "  # Convert email texts to a list of strings\n",
    "  training_emails = [' '.join(email) for email, _ in train_set]\n",
    "  testing_emails = [' '.join(email) for email, _ in test_set]\n",
    "\n",
    "  # Use TF-IDF vectorizer to convert emails to feature vectors\n",
    "  vectorizer = TfidfVectorizer()\n",
    "  X_train = vectorizer.fit_transform(training_emails)\n",
    "  X_test = vectorizer.transform(testing_emails)\n",
    "  \n",
    "  # Get the corresponding labels\n",
    "  y_train = [label for _, label in train_set]\n",
    "  y_test = [label for _, label in test_set]\n",
    "\n",
    "  # Train classifier\n",
    "  classifier = RandomForestClassifier() if rf else SVC(kernel='linear') if svm else MultinomialNB()\n",
    "  classifier.fit(X_train, y_train)\n",
    "\n",
    "  # Predict labels for testing set\n",
    "  y_pred = classifier.predict(X_test)\n",
    "\n",
    "  print(\"\\nAccuracy:\", classifier.score(X_test, y_test))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred, pos_label='spam'))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred, pos_label='spam'))\n",
    "  print(\"F-measure:\", f1_score(y_test, y_pred, pos_label='spam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aaaba7e-a14e-4630-9270-29ede1f364c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read spam and ham files, train and test a classifier \n",
    "def processspamham(dirPath,limitStr):\n",
    "  # convert the limit argument from a string to an int\n",
    "  limit = int(limitStr)\n",
    "  \n",
    "  # start lists for spam and ham email texts\n",
    "  hamtexts = []\n",
    "  spamtexts = []\n",
    "  os.chdir(dirPath)\n",
    "  # process all files in directory that end in .txt up to the limit\n",
    "  #    assuming that the emails are sufficiently randomized\n",
    "  for file in os.listdir(\"./spam\"):\n",
    "    if (file.endswith(\".txt\")) and (len(spamtexts) < limit):\n",
    "      # open file for reading and read entire file into a string\n",
    "      f = open(\"./spam/\"+file, 'r', encoding=\"latin-1\")\n",
    "      spamtexts.append (f.read())\n",
    "      f.close()\n",
    "  for file in os.listdir(\"./ham\"):\n",
    "    if (file.endswith(\".txt\")) and (len(hamtexts) < limit):\n",
    "      # open file for reading and read entire file into a string\n",
    "      f = open(\"./ham/\"+file, 'r', encoding=\"latin-1\")\n",
    "      hamtexts.append (f.read())\n",
    "      f.close()\n",
    "  \n",
    "  # print number emails read\n",
    "  print (\"Number of spam files:\",len(spamtexts))\n",
    "  print (\"Number of ham files:\",len(hamtexts))\n",
    "  print\n",
    "\n",
    "  # create list of mixed spam and ham email documents as (list of words, label)\n",
    "  emaildocs = []\n",
    "  # add all the spam\n",
    "  for spam in spamtexts:\n",
    "    tokens = nltk.word_tokenize(spam)\n",
    "    emaildocs.append((tokens, 'spam'))\n",
    "  # add all the regular emails\n",
    "  for ham in hamtexts:\n",
    "    tokens = nltk.word_tokenize(ham)\n",
    "    emaildocs.append((tokens, 'ham'))\n",
    "  \n",
    "  # randomize the list\n",
    "  random.shuffle(emaildocs)\n",
    "  \n",
    "  # print a few token lists\n",
    "  for email in emaildocs[:4]:\n",
    "    print (email)\n",
    "    print\n",
    "      \n",
    "  # possibly filter tokens\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  filtered_tokens = [word for email in emaildocs for word in email[0] if word.lower() not in stop_words]\n",
    "\n",
    "  # continue as usual to get all words and create word features\n",
    "  all_words = nltk.FreqDist(filtered_tokens)\n",
    "  word_features = list(all_words.keys())[:2000]\n",
    "\n",
    "  return emaildocs, word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2c1e8d-ba02-4d5f-bf5b-841f24c1827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_nb(corpus_dir, limit):\n",
    "  #Multinomial Naive Bayes\n",
    "  print(\"\\nMultinomial Naive Bayes\\n\")\n",
    "  emaildocs, word_features = processspamham(corpus_dir, limit)\n",
    "  classifier_train_result(emaildocs, word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba2abba-43f1-4463-81ce-366596e342a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_nb_ps(corpus_dir, limit):\n",
    "  #Multinomial Naive Bayes with porter stemmer\n",
    "  print(\"\\nMultinomial Naive Bayes with Porter Stemmer\\n\")\n",
    "  emaildocs, word_features = processspamham(corpus_dir, limit)\n",
    "  classifier_train_result(emaildocs, word_features, ps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52c6e2b-9381-4969-be68-34bfcdff5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_nb_wc(corpus_dir, limit):\n",
    "  #Multinomial Naive Bayes with word count\n",
    "  print(\"\\nMultinomial Naive Bayes (word count) with Porter Stemmer\\n\")\n",
    "  emaildocs, word_features = processspamham(corpus_dir, limit)\n",
    "  classifier_train_result(emaildocs, word_features, wc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "803d070e-771f-4dfb-8c2a-f14d758c07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_nb_lem(corpus_dir, limit):\n",
    "  #Multinomial Naive Bayes with lemmatizer\n",
    "  print(\"\\nMultinomial Naive Bayes with Lemmatizer\\n\")\n",
    "  emaildocs, word_features = processspamham(corpus_dir, limit)\n",
    "  classifier_train_result(emaildocs, word_features, lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50503ce4-b5ce-4fd7-97e5-a93829a65b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_ps(corpus_dir, limit):\n",
    "  #SVM with porter stemmer\n",
    "  print(\"\\nSVM with Porter Stemmer\\n\")\n",
    "  emaildocs, word_features = processspamham(corpus_dir, limit)\n",
    "  classifier_train_result(emaildocs, word_features, ps=True, svm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "962fea6f-d144-4fc4-bd60-d19f205d2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(corpus_dir, limit):\n",
    "  #Random Forest\n",
    "  print(\"\\nRandom Forest Classifier\\n\")\n",
    "  emaildocs, word_features = processspamham(corpus_dir, limit)\n",
    "  classifier_train_result(emaildocs, word_features, rf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "069f69d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes\n",
      "\n",
      "Number of spam files: 1000\n",
      "Number of ham files: 1000\n",
      "(['Subject', ':', 'enron', 'actuals', 'for', 'dec', '.', '27', ',', '2000', 'dec', '.', '27', ',', '2000', 'teco', 'tap', '30', '.', '000', '/', 'enron', ';', '120', '.', '000', '/', 'hpl', 'gas', 'daily', 'lsp', 'hpl', 'katy', 'i', '/', 'c', '30', '.', '000', '/', 'enron'], 'ham')\n",
      "(['Subject', ':', 'select', 'eshopping', 'for', 'medicines', 'and', 'take', 'advantage', 'of', 'the', 'specials', 'at', 'our', 'cyberstore', '.', 'if', 'you', 'have', 'a', 'tight', 'budget', 'and', 'still', 'prefer', 'quality', 'tablets', 'to', 'alleviate', 'the', 'pain', ',', 'seek', 'a', 'better', 'resolution', '.', 'we', 'provide', 'the', 'pricing', 'that', 'reduce', 'your', 'expenses', 'on', 'dr', '.', 'prescribed', 'rememdies', 'for', 'pain', ',', 'swelling', ',', 'dysfunction', 'of', 'the', 'erectile', 'member', ',', 'stress', ',', 'raised', 'cholesterol', ',', 'man', \"'\", 's', 'care', ',', 'muscle', 'relaxing', 'and', 'sleeping', 'disorders', '.', 'check', 'our', 'store', 'and', 'have', 'the', 'rxmeds', 'sent', 'to', 'you', 'in', 'a', 'timely', 'manner', '.', 'you', 'can', 'ignore', 'the', 'over', 'priced', 'taablets', 'sold', 'at', 'your', 'local', 'stores', '.', 'this', 'cyber', 'store', 'provides', 'customers', 'additional', 'benefits', 'as', 'well', 'as', 'reduced', 'pricing', '.', 'at', 'our', 'store', ',', 'customer', \"'\", 's', 'case', 'details', 'will', 'be', 'complementally', 'checked', 'by', 'licensed', 'physicians', '.', 'http', ':', '/', '/', 'dl', '.', 'gg', '.', 'passwordtourzone', '.', 'com', '/', 'yip', '/', 'start', 'novv', 'and', 'check', 'all', 'the', 'items', 'at', 'our', 'pharrn', '-', 'site', '.', 'ars', 'and', 'old', 'tea', '-', 'chests', 'the', 'sounds', 'were', 'retreating', ',', 'and', 'anne', 'distinguished', 'no', 'more', '.', 'we', 'had', 'better', 'put', 'it', 'off', '.', 'charles', ',', 'you', 'had', 'much', 'better', 'go', 'back', ',', 'when', 'there', 'is', 'nobody', 'in', 'there', 'with', 'a', 'diml', 'her', 'own', 'emotions', 'still', 'kept', 'her', 'fixed', '.', 'she', 'had', 'much', 'to', 'recover', 'from', ',', 'y', '-', 'burning', 'light', ',', 'lett', '2', 'ing', 'a', 'mouldy', 'air', 'come', 'out', 'of', '4', 'the', 'door', ',', 'in', 'which', 'there', 'is', 'th'], 'spam')\n",
      "(['Subject', ':', 'viewsonic', 'airpanel', 'vl', '50', '15', '-', 'inch', 'smart', 'display', 'and', 'dock', '@', '$', '575', '.', '00', 'only', '!', '!', 'airpanel', 'vl', '50', '15', '-', 'inch', '$', '575', '.', '00', 'only', '!', '!', 'smart', 'display', 'dock', 'visit', ':', 'http', ':', '/', 'www', '.', 'computron', '-', 'me', '.', 'com', 'for', 'deals', '!', 'viewsonic', 'airpanel', 'vl', '50', '15', '-', 'inch', 'smart', 'display', 'and', 'dock', 'the', 'viewsonic', 'airpanel', 'vl', '50', 'smart', 'display', 'is', 'a', 'wireless', ',', 'touch', '-', 'screen', 'monitor', 'that', 'lets', 'you', 'access', 'and', 'use', 'your', 'home', 'computer', 'from', 'different', 'rooms', 'in', 'your', 'home', '.', 'it', 'features', 'a', '15', '-', 'inch', 'touch', 'screen', ',', 'intel', '400', 'mhz', 'xscale', 'processor', ',', '64', 'mb', 'sdram', ',', 'microsoft', 'windows', 'ce', 'operating', 'system', ',', 'and', 'more', '!', 'it', 'includes', 'an', 'airsync', 'usb', 'wireless', 'adapter', 'so', 'you', 'can', 'enjoy', 'the', 'freedom', 'of', 'wireless', 'connectivity', '.', 'this', 'kit', 'comes', 'complete', 'with', 'an', 'airpanel', 'dock', 'for', 'your', 'monitor', '.', 'easily', 'charge', 'your', 'airpanel', 'battery', 'while', 'docked', '.', 'it', 'features', 'front', 'on', '-', 'screen', 'display', 'controls', ',', 'usb', 'ports', ',', 'and', 'a', 'compact', 'design', 'that', 'saves', 'desk', 'space', '.', 'order', 'yours', 'today', '!', 'general', 'features', ':', '-', 'intel', '400', 'mhz', 'xscale', 'processor', '-', 'microsoft', 'windows', 'ce', 'operating', 'system', '-', '32', 'mb', 'rom', '-', '64', 'mb', 'sdram', '-', '15', '-', 'inch', 'transmissive', 'display', 'w', '/', '1024', 'x', '768', 'resolution', '-', 'integrated', '802', '.', '11', 'b', 'wireless', 'networking', '-', 'lithium', '-', 'ion', 'battery', '-', 'energy', '-', 'star', 'compliant', 'your', 'one', 'stop', 'distributorjebel', 'ali', 'duty', 'free', 'zonedubai', ',', 'uae', '.', 'www', '.', 'computron', '-', 'me', '.', 'com', 'for', 'latest', 'clearance', 'sale', 'listing', 'contact', 'our', 'sales', 'department', '.', 'only', 'limited', 'quantities', 'available', 'on', 'selected', 'specials', '!', '!', '!', '!', 'for', 'further', 'details', 'please', 'send', 'your', 'enquiries', 'to', ':', 'dealers', '@', 'emirates', '.', 'net', '.', 'aeor', 'contact', 'via', 'www', '.', 'computron', '-', 'me', '.', 'com', 'compaq', 'hewlett', 'packard', '3', 'com', 'dell', 'intel', 'iomega', 'epson', 'aopen', 'creative', 'toshiba', 'apc', 'cisco', 'us', 'robotics', 'microsoft', 'canon', 'intellinet', 'targus', 'viewsonic', 'ibm', 'sony', '-', '-', '-', '-', '-', '-', '-', 'and', 'lots', 'more', '!', '!', '!', 'if', 'you', 'have', 'any', 'complaints', '/', 'suggestions', 'contact', ':', 'customerservice', '@', 'computron', '-', 'me', '.', 'com', 'tel', '+', '971', '4', '8834464', 'all', 'prices', 'in', 'u', '.', 's', '.', 'dollars', ',', 'ex', '-', 'works', ',', 'fax', '+', '971', '4', '8834454', 'jebel', 'ali', 'duty', 'free', 'zone', 'www', '.', 'computron', '-', 'me', '.', 'com', 'prices', 'and', 'availability', 'subject', 'to', 'change', 'usa', '-', 'canada', 'u', '.', 'a', '.', 'e', '.', 'without', 'notice', '.', 'to', 'receive', 'our', 'special', 'offers', 'in', 'plain', 'text', 'format', 'reply', 'to', 'this', 'mail', 'with', 'the', 'request', '*', 'for', 'export', 'only', '*', 'this', 'email', 'can', 'not', 'be', 'considered', 'spam', 'as', 'long', 'as', 'we', 'include', ':', 'contact', 'information', 'remove', 'instructions', '.', 'this', 'message', 'is', 'intended', 'for', 'dealer', 'and', 'resellers', 'only', '.', 'if', 'you', 'have', 'somehow', 'gotten', 'on', 'this', 'list', 'in', 'error', ',', 'or', 'for', 'any', 'other', 'reason', 'would', 'like', 'to', 'be', 'removed', ',', 'please', 'reply', 'with', '``', 'remove', \"''\", 'in', 'the', 'subject', 'line', 'of', 'your', 'message', '.', 'this', 'message', 'is', 'being', 'sent', 'to', 'you', 'in', 'compliance', 'with', 'the', 'federal', 'legislation', 'for', 'commercial', 'e', '-', 'mail', '(', 'h', '.', 'r', '.', '4176', '-', 'section', '101', 'paragraph', '(', 'e', ')', '(', '1', ')', '(', 'a', ')', 'and', 'bill', 's', '.', '1618', 'title', 'iii', 'passed', 'by', 'the', '105', 'th', 'u', '.', 's', '.', 'congress', '.', 'all', 'logos', 'and', 'trademarks', 'are', 'the', 'property', 'of', 'their', 'respective', 'owners', 'products', 'may', 'not', 'be', 'exactly', 'as', 'shown', 'above', '-', '-', 'to', 'unsubscribe', 'from', ':', 'computron', '3', ',', 'just', 'follow', 'this', 'link', ':', 'click', 'the', 'link', ',', 'or', 'copy', 'and', 'paste', 'the', 'address', 'into', 'your', 'browser', '.', 'please', 'give', 'it', 'atleast', '48', 'hours', 'for', 'unsubscription', 'to', 'be', 'effective', '.'], 'spam')\n",
      "(['Subject', ':', 'tadalafil', 'soft', 'tabs', '-', 'great', 'results', '!', 'hi', '!', 'we', 'have', 'a', 'new', 'product', 'that', 'we', 'offer', 'to', 'you', ',', 'c', '_', 'i', '_', 'a', '_', 'l', '_', 'i', '_', 's', 'soft', 'tabs', ',', 'cialis', 'soft', 'tabs', 'is', 'the', 'new', 'impotence', 'treatment', 'drug', 'that', 'everyone', 'is', 'talking', 'about', '.', 'soft', 'tabs', 'acts', 'up', 'to', '36', 'hours', ',', 'compare', 'this', 'to', 'only', 'two', 'or', 'three', 'hours', 'of', 'viagra', 'action', '!', 'the', 'active', 'ingredient', 'is', 'tadalafil', ',', 'same', 'as', 'in', 'brand', 'cialis', '.', 'simply', 'dissolve', 'half', 'a', 'pill', 'under', 'your', 'tongue', ',', '10', 'min', 'before', 'sex', ',', 'for', 'the', 'best', 'erections', 'you', \"'\", 've', 'ever', 'had', '!', 'soft', 'tabs', 'also', 'have', 'less', 'sidebacks', '(', 'you', 'can', 'drive', 'or', 'mix', 'alcohol', 'drinks', 'with', 'them', ')', '.', 'you', 'can', 'get', 'it', 'at', ':', 'http', ':', '/', '/', 'ejrhxw', '322', '.', 'com', '/', 'soft', '/', 'no', 'thanks', ':', 'http', ':', '/', '/', 'ejrhxw', '322', '.', 'com', '/', 'rr', '.', 'php'], 'spam')\n",
      "\n",
      "Simple Classifier accuracy: 0.9275\n",
      "\n",
      "Accuracy: 0.4775\n",
      "Precision: 0.4775\n",
      "Recall: 1.0\n",
      "F-measure: 0.6463620981387478\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "commandline interface takes a directory name with ham and spam subdirectories\n",
    "   and a limit to the number of emails read each of ham and spam\n",
    "It then processes the files and trains a spam detection classifier.\n",
    "\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    corpus_dir = '/Users/prasunabhishek/Desktop/Syracuse Course Content - MS in Business Analytics/Syracuse Winter sem - NLP - Winter 2023-24/Project/EmailSpamCorpora/corpus'\n",
    "    limit = 1000\n",
    "    multi_nb(corpus_dir, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a056b798-ebe9-4079-b6e6-9989ab8ba520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes with Porter Stemmer\n",
      "\n",
      "Number of spam files: 1000\n",
      "Number of ham files: 1000\n",
      "(['Subject', ':', 'sterling', 'balance', 'sheet', 'strengthens', 'underpriced', 'stock', 'now', 'that', 'oil', 'and', 'gas', 'has', 'entered', 'a', 'long', '-', 'term', 'bull', 'market', ',', 'our', 'speciaity', 'in', 'pinpointing', 'the', 'hottest', 'companies', 'of', 'the', 'few', 'remaining', 'undervalued', 'energy', 'plays', 'has', 'produced', 'soaring', 'returns', '.', 'montana', 'oil', 'and', 'gas', ',', 'inc', '.', '(', 'mogi', ')', 'to', 'expiore', 'further', 'opportunities', 'in', 'aiberta', 'canada', ',', 'a', 'is', 'an', 'energy', 'deveioper', 'in', 'canada', \"'\", 's', 'most', 'highly', 'coveted', 'reservoirs', 'with', 'generating', 'potential', 'of', 'miliions', 'per', 'week', 'symbol', '-', 'mogi', 'price', '-', '.', '47', 'increased', '11', '%', 'last', 'three', 'day', ',', 'rating', '-', 'strongbuy', 'how', 'much', 'it', 'wi', '|', '|', 'up', 'again', '?', 'the', 'vaiue', 'of', 'mogi', \"'\", 's', 'shares', 'wil', '|', 'skyrocket', ':', '1', '.', 'price', 'charts', 'confirm', 'oi', '|', 'prices', 'are', 'experiencing', 'the', 'strongest', 'buil', 'market', 'in', 'a', 'generation', '.', '2', '.', 'natural', 'gas', 'prices', 'have', 'tripled', 'in', 'the', '|', 'ast', 'two', 'years', '.', '3', '.', 'with', 'muitipie', 'projects', 'in', 'high', '-', 'gear', 'and', 'the', 'expanding', 'production', 'on', 'reserves', 'worth', 'muiti', '-', 'mi', '|', '|', 'ions', ',', 'mogi', 'is', 'se', '|', '|', 'ing', 'for', '|', 'ess', 'than', '1', '/', '4', 'the', 'vaiue', 'of', 'its', 'assets', '.', '4', '.', 'montana', 'oil', 'and', 'gas', 'speciaiizes', 'in', 'using', 'new', 'technoiogy', 'to', 'turn', 'unproductive', 'oi', '|', 'and', 'gas', 'deposits', 'into', 'profitable', 'enterprises', '.', 'aiready', 'shares', 'in', 'the', 'oil', 'and', 'gas', 'sector', 'are', 'rising', 'faster', 'than', 'the', 'overal', '|', 'market', '.', 'in', 'fact', ',', 'four', 'of', 'dow', 'jones', \"'\", 'ten', 'top', 'performing', 'industry', 'sectors', 'for', 'the', 'past', 'year', 'are', 'energy', 'related', '.', 'but', 'it', \"'\", 's', 'in', 'the', 'mid', '-', 'sized', 'explorers', 'and', 'developers', '|', 'ike', 'montana', 'oi', '|', '(', 'mogi', ')', 'that', 'the', 'biggest', 'gains', 'are', 'being', 'made', '.', 'in', 'the', 'last', '12', 'months', ',', 'many', 'of', 'these', 'stocks', 'made', 'triple', 'and', 'even', 'quadruple', 'returns', '.', 'vancouver', ',', 'march', '11', ',', '2', 'oo', '5', '-', '(', 'mogi', ')', 'president', 'peter', 'sanders', 'would', '|', 'ike', 'to', 'announce', 'that', 'a', 'decision', 'has', 'been', 'made', 'to', 'explore', 'further', 'opportunities', 'in', 'the', 'alberta', 'canada', 'region', 'where', 'the', 'company', 'currentiy', 'has', 'interests', 'in', 'three', 'projects', '.', 'the', 'company', 'has', 'become', 'aware', 'of', 'existing', 'opportunities', 'to', 'partner', 'in', ',', 'or', 'acquire', '|', 'eases', ',', 'which', 'may', 'include', 'producing', 'welis', 'and', 'or', 'expioratory', 'programs', 'which', 'wi', '|', '|', 'strengthen', 'montana', '\\x12', 's', 'position', 'with', 'energy', ',', 'cash', 'oriented', 'investment', 'banking', 'groups', '.', 'one', 'of', 'the', 'most', 'effective', 'ways', 'to', 'acquire', 'financia', '|', 'partners', 'for', 'drilling', 'programs', 'invoives', 'existing', 'production', 'of', 'oil', 'and', 'or', 'gas', 'in', 'these', 'programs', '.', 'this', 'wiil', 'significantiy', 'lessens', 'the', 'risk', 'for', 'the', 'investment', 'group', ',', 'hence', 'encouraging', 'financial', 'participation', 'as', 'well', 'as', 'speeding', 'up', 'the', 'process', 'of', 'commitment', 'by', 'the', 'investment', 'group', '.', 'the', 'sylvan', 'lake', 'project', 'will', 'begin', 'very', 'shortly', 'the', 'company', 'and', 'its', 'partners', 'have', 'secured', 'a', 'driiling', 'rig', 'and', 'are', 'only', 'waiting', 'for', 'a', 'temporary', 'road', 'ban', 'to', 'be', 'lifted', '.', 'the', 'rig', 'is', 'currentiy', 'sitting', 'in', 'red', 'deer', 'aiberta', 'a', 'mere', '30', 'miles', 'from', 'syivan', 'lake', '.', 'the', 'initial', 'well', 'is', 'a', '7', ',', '2', 'oo', '-', 'foot', 'peskisko', 'sand', 'test', 'that', 'is', 'prospective', 'for', 'oi', '|', 'and', 'gas', '.', 'it', 'is', 'expected', 'to', 'take', 'approximateiy', '10', 'to', '12', 'days', 'to', 'dril', '|', 'and', 'test', 'the', 'initia', '|', 'wel', '|', '.', 'each', 'deveiopment', 'weil', 'has', 'probabie', 'production', 'of', '15', 'o', 'barreis', 'of', 'oil', 'per', 'day', 'and', '75', 'o', 'miilion', 'cubic', 'feet', 'gas', 'per', 'day', 'with', 'reserves', 'in', 'excess', 'of', '1', 'biilion', 'cubic', 'feet', 'gas', 'and', '3', 'oo', ',', '0', 'oo', 'barreis', 'of', 'oi', '|', '.', 'there', 'are', 'four', 'other', 'pay', 'zones', 'that', 'are', 'prospective', 'for', 'gas', '.', 'the', 'average', 'wel', '|', 'in', 'the', 'syivan', 'lake', 'fieid', 'has', 'produced', '50', 'o', 'barrels', 'of', 'oi', '|', 'per', 'day', 'with', 'over', 'one', 'mi', '|', '|', 'ion', 'cubic', 'feet', 'of', 'gas', 'per', 'day', '.', 'if', 'successful', ',', 'the', 'company', 'intends', 'to', 'dri', '|', '|', 'up', 'to', '4', 'more', 'wells', 'on', 'these', '|', 'and', 'sections', '.', 'for', 'more', 'detaiied', 'information', 'on', 'this', 'project', 'please', 'see', 'news', 'reiease', 'dated', 'feb', '.', '7', 'th', ',', '2', 'oo', '5', '.', 'an', 'announcement', 'wiil', 'be', 'made', 'immediateiy', 'upon', 'the', 'commencement', 'of', 'driiling', '.', 'the', 'company', 'is', 'aiso', 'pieased', 'to', 'report', 'that', 'the', 'tie', 'in', 'of', 'its', 'west', 'lock', 'project', 'did', 'start', 'several', 'days', 'ago', 'and', 'it', 'is', 'anticitaped', 'that', 'this', 'will', 'be', 'complete', 'some', 'time', 'in', 'the', 'next', 'couple', 'of', 'days', '.', 'peter', 'sanders', 'notes', '\\x13', 'the', 'compietion', 'and', 'tie', 'in', 'of', 'the', 'west', 'lock', 'project', 'has', 'ran', 'into', 'numerous', 'delays', ',', 'however', ',', 'this', 'wel', '|', 'wil', '|', 'be', 'tied', 'in', 'and', 'the', 'company', 'wil', '|', 'be', 'se', '|', '|', 'ing', 'gas', 'by', 'next', 'week', 'thus', 'generating', 'cash', 'flow', 'for', 'the', 'company', '\\x14', 'the', 'company', 'wi', '|', '|', 'update', 'its', 'shareholders', 'when', 'it', 'has', 'heard', 'from', 'its', 'partner', 'in', 'regards', 'to', 'completion', '.', 'wi', '|', '|', 'mogi', 'expiode', 'higher', 'as', 'more', 'and', 'more', 'investors', 'become', 'aware', 'of', 'the', 'stock', '?', 'if', 'you', 'think', 'so', ',', 'you', 'may', 'not', 'want', 'to', 'wait', 'unti', '|', 'it', 'is', 'too', 'late', '.', 'remember', ',', 'timing', 'your', 'trade', 'is', 'critica', '|', '.', 'good', 'luck', 'and', 'successfu', '|', 'trading', '.', 'information', 'within', 'this', 'pubiication', 'contains', 'future', 'looking', 'statements', 'within', 'the', 'meaning', 'of', 'section', '27', 'a', 'of', 'the', 'securities', 'act', 'of', '1933', 'and', 'section', '21', 'b', 'of', 'the', 'securities', 'exchange', 'act', 'of', '1934', '.', 'any', 'statements', 'thatexpress', 'or', 'invoive', 'discussions', 'with', 'respect', 'to', 'predictions', ',', 'expectations', ',', 'beliefs', ',', 'plans', ',', 'projections', ',', 'objectives', ',', 'goais', ',', 'assumptions', 'or', 'futureevents', 'or', 'performance', 'are', 'not', 'statements', 'of', 'historica', '|', 'fact', 'and', 'may', 'be', 'future', 'looking', 'statements', '.', 'future', '|', 'ooking', 'statements', 'are', 'based', 'on', 'expectations', ',', 'estimates', 'and', 'projections', 'at', 'the', 'time', 'the', 'statements', 'are', 'made', 'that', 'invoive', 'a', 'number', 'of', 'risks', 'and', 'uncertainties', 'which', 'couid', 'cause', 'actua', '|', 'results', 'or', 'events', 'to', 'differ', 'materialiy', 'from', 'those', 'presently', 'anticipated', '.', 'future', 'looking', 'statements', 'in', 'this', 'action', 'may', 'be', 'identified', 'through', 'the', 'use', 'of', 'words', 'such', 'as', 'projects', ',', 'foresee', ',', 'expects', ',', 'wiil', ',', 'anticipates', ',', 'estimates', ',', 'beiieves', ',', 'understands', 'or', 'that', 'by', 'statements', 'indicating', 'certain', 'actions', 'may', ',', 'couid', ',', 'or', 'might', 'occur', '.', 'these', 'future', '-', 'looking', 'statements', 'are', 'based', 'on', 'information', 'currently', 'availabie', 'and', 'are', 'subject', 'to', 'a', 'number', 'of', 'risks', ',', 'uncertainties', 'and', 'other', 'factors', 'that', 'could', 'cause', 'mogi', '\\x12', 's', 'actua', '|', 'resuits', ',', 'performance', ',', 'prospects', 'or', 'opportunities', 'to', 'differ', 'materia', '|', '|', 'y', 'from', 'those', 'expressed', 'in', ',', 'or', 'impiied', 'by', ',', 'these', 'future', '-', 'looking', 'statements', '.', 'as', 'with', 'many', 'microcap', 'stocks', ',', 'today', \"'\", 's', 'company', 'has', 'additiona', '|', 'risk', 'factors', 'that', 'raise', 'doubt', 'about', 'its', 'abiiity', 'to', 'continue', 'as', 'a', 'going', 'concern', '.', 'these', 'risks', ',', 'uncertainties', 'and', 'other', 'factors', 'include', ',', 'without', 'limitation', ',', 'the', 'company', \"'\", 's', 'growth', 'expectations', 'and', 'ongoing', 'funding', 'requirements', ',', 'and', 'specifically', ',', 'the', 'company', \"'\", 's', 'growth', 'prospects', 'with', 'scaiabie', 'customers', '.', 'other', 'risks', 'inciude', 'the', 'company', \"'\", 's', '|', 'imited', 'operating', 'history', ',', 'the', 'company', \"'\", 's', 'history', 'of', 'operating', 'losses', ',', 'consumers', \"'\", 'acceptance', ',', 'the', 'company', \"'\", 's', 'use', 'of', 'licensed', 'technologies', ',', 'risk', 'of', 'increased', 'competition', ',', 'the', 'potentia', '|', 'need', 'for', 'additional', 'financing', ',', 'the', 'conditions', 'and', 'terms', 'of', 'any', 'financing', 'that', 'is', 'consummated', ',', 'the', 'limited', 'trading', 'market', 'for', 'the', 'company', \"'\", 's', 'securities', ',', 'the', 'possible', 'volatiiity', 'of', 'the', 'company', \"'\", 's', 'stock', 'price', ',', 'the', 'concentration', 'of', 'ownership', ',', 'and', 'the', 'potentia', '|', 'fluctuation', 'in', 'the', 'company', \"'\", 's', 'operating', 'results', '.', 'the', 'pubiisher', 'of', 'this', 'report', 'does', 'not', 'represent', 'that', 'the', 'information', 'contained', 'in', 'this', 'message', 'states', 'a', '|', '|', 'materia', '|', 'facts', 'or', 'does', 'not', 'omit', 'a', 'material', 'fact', 'necessary', 'to', 'make', 'the', 'statements', 'therein', 'not', 'misleading', '.', 'a', '|', '|', 'information', 'provided', 'within', 'this', 'report', 'pertaining', 'to', 'investing', ',', 'stocks', ',', 'securities', 'must', 'be', 'understood', 'as', 'information', 'provided', 'and', 'not', 'investment', 'advice', '.', 'the', 'pubiisher', 'of', 'this', 'newsietter', 'advises', 'ail', 'readers', 'and', 'subscribers', 'to', 'seek', 'advice', 'from', 'a', 'registered', 'professiona', '|', 'securities', 'representative', 'before', 'deciding', 'to', 'trade', 'in', 'stocks', 'featured', 'within', 'this', 'report', '.', 'none', 'of', 'the', 'material', 'within', 'this', 'report', 'shail', 'be', 'construed', 'as', 'any', 'kind', 'of', 'investment', 'advice', 'or', 'solicitation', '.', 'many', 'of', 'these', 'companies', 'are', 'on', 'the', 'verge', 'of', 'bankruptcy', '.', 'you', 'can', 'lose', 'al', '|', 'your', 'money', 'by', 'investing', 'in', 'this', 'stock', '.', 'the', 'pubiisher', 'of', 'this', 'report', 'is', 'not', 'a', 'registered', 'investment', 'expert', '.', 'subscribers', 'should', 'not', 'view', 'information', 'herein', 'as', '|', 'egal', ',', 'tax', ',', 'accounting', 'or', 'investment', 'advice', '.', 'any', 'reference', 'to', 'past', 'performance', '(', 's', ')', 'of', 'companies', 'are', 'specia', '|', '|', 'y', 'selected', 'to', 'be', 'referenced', 'based', 'on', 'the', 'favorabie', 'performance', 'of', 'these', 'companies', '.', 'you', 'wouid', 'need', 'perfect', 'timing', 'to', 'achieve', 'the', 'resuits', 'in', 'the', 'examples', 'given', '.', 'there', 'can', 'be', 'no', 'assurance', 'of', 'that', 'happening', '.', 'remember', ',', 'as', 'aiways', ',', 'past', 'performance', 'is', 'not', 'indicative', 'of', 'future', 'resuits', 'and', 'a', 'thorough', 'due', 'diiigence', 'effort', ',', 'inciuding', 'a', 'review', 'of', 'a', 'company', \"'\", 's', 'filings', 'at', 'sec', 'gov', 'or', 'edgar', '-', 'oniine', 'com', 'when', 'avaiiable', ',', 'shouid', 'be', 'compieted', 'prior', 'to', 'investing', '.', 'al', '|', 'factua', '|', 'information', 'in', 'this', 'report', 'was', 'gathered', 'from', 'public', 'sources', ',', 'inciuding', 'but', 'not', 'limited', 'to', 'company', 'websites', 'and', 'company', 'press', 'reieases', '.', 'the', 'pubiisher', 'discloses', 'the', 'receipt', 'of', 'fifteen', 'thousand', 'doilars', 'from', 'a', 'third', 'party', ',', 'not', 'an', 'officer', ',', 'director', ',', 'or', 'affiiiate', 'shareholder', 'ofthe', 'company', 'for', 'the', 'preparation', 'of', 'this', 'oniine', 'report', '.', 'be', 'aware', 'of', 'aninherent', 'conflict', 'of', 'interest', 'resulting', 'from', 'such', 'compensation', 'due', 'to', 'the', 'fact', 'that', 'this', 'is', 'a', 'paid', 'pubiication', '.', 'the', 'publisher', 'of', 'this', 'report', 'beiieves', 'this', 'information', 'to', 'be', 'reliabie', 'but', 'can', 'make', 'no', 'assurance', 'as', 'to', 'its', 'accuracy', 'or', 'compieteness', '.', 'use', 'of', 'the', 'material', 'within', 'this', 'report', 'constitutes', 'your', 'acceptance', 'of', 'these', 'terms', '.', 'if', 'you', 'wish', 'to', 'stop', 'future', 'mailings', ',', 'or', 'if', 'you', 'feel', 'you', 'have', 'been', 'wrongfully', 'piaced', 'in', 'our', 'membership', ',', 'piease', 'go', 'here', 'or', 'send', 'a', 'blank', 'e', 'mai', '|', 'with', 'no', 'thanks', 'in', 'the', 'subject', 'to', '(', '-', 'stock', '37', '@', 'yahoo', '.', 'com', '-', ')'], 'spam')\n",
      "(['Subject', ':', 'deal', 'number', '109660', 'mark', 'has', 'informed', 'me', 'that', 'one', 'of', 'you', 'would', 'handle', 'anything', 'prior', 'to', '5', '/', '00', 'on', 'oasis', '.', 'please', 'see', 'below', '.', 'let', 'me', 'know', 'if', 'i', 'need', 'to', 'provide', 'further', 'information', '.', 'thanks', '!', 'karen', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'forwarded', 'by', 'karen', 'lindley', '/', 'corp', '/', 'enron', 'on', '08', '/', '11', '/', '2000', '04', ':', '01', 'pm', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'from', ':', 'karen', 'lindley', '08', '/', '10', '/', '2000', '03', ':', '38', 'pm', 'to', ':', 'mark', 'mccoy', '/', 'corp', '/', 'enron', '@', 'enron', 'cc', ':', 'subject', ':', 'deal', 'number', '109660', 'hi', 'mark', '!', 'another', 'interconnect', 'issue', '-', '7', '/', '99', ':', 'can', 'you', 'please', 'take', 'a', 'look', 'at', 'deal', '109660', '?', 'it', 'is', 'set', 'up', 'with', 'a', 'transport', 'usage', 'ticket', ',', 'however', 'is', 'a', 'brokered', 'deal', '.', 'i', 'am', 'not', 'sure', 'if', 'it', 'is', 'pathed', 'incorrectly', 'or', 'if', 'possibly', 'the', 'deal', 'is', 'set', 'up', 'incorrectly', '.', 'let', 'me', 'know', 'your', 'thoughts', '.', 'karen'], 'ham')\n",
      "(['Subject', ':', 'ces', 'changes', 'gulf', 'energy', 'pipeline', 'tejas', 'plant', 'from', '81', 'to', '52', 'trevino', 'plant', 'from', '4890', 'to', '1361', 'comiats', 'south', 'from', '403', 'to', '28', 'gulf', 'plains', 'from', '10939', 'to', '7876', 'corpus', 'christie', 'virginia', 'from', '379', 'to', '165', 'midcon', 'greta', 'tom', 'oconner', 'from', '2243', 'to', '1392'], 'ham')\n",
      "(['Subject', ':', 'breaking', 'news', 'fbgo', '``', 'wan', 'na', 'be', 'a', 'millionaire', '``', 'isrntv', '*', 'news', 'bulletin', '*', 'first', 'bingo', 'inc', 'otcbb', ':', 'fbgo', '.', 'ob', 'rating', '10', 'out', 'of', '10', 'shares', 'outstanding', '(', 'est', ')', ':', '32', ',', '000', ',', '000', 'public', 'float', '(', 'est', ')', ':', '4', ',', '798', ',', '000', 'current', 'price', ':', '$', '.', '39', '6', 'month', 'price', 'projection', ':', '$', '1', '.', '80', '52', 'week', 'high', '$', '1', '.', '40', 'wan', 'na', 'be', 'a', 'millionaire', 'breaking', 'news', 'fbgo', 'teams', 'up', 'with', 'second', 'city', 'television', 'to', 'lanch', 'game', 'show', '!', 'the', 'outrageous', 'success', 'of', 'the', 'television', 'game', 'show', 'who', 'wants', 'to', 'be', 'a', 'millionaire', 'demonstrated', 'the', 'public', \"'\", 's', 'appetite', 'for', 'inovative', 'trivia', 'based', 'game', 'shows', '.', 'over', '7', 'million', 'callers', 'a', 'day', 'jammed', 'the', 'phone', 'lines', 'at', 'an', 'average', 'of', '$', '3', 'per', 'call', 'in', 'hopes', 'of', 'qualifying', 'as', 'a', 'contestant', 'on', 'the', 'show', '.', 'fbgo', 'the', 'creator', 'ofc', 'boast', 'of', 'a', 'superior', 'concept', 'utilizing', 'bingo', ',', 'the', 'worlds', 'most', 'recognized', 'game', ',', 'trivia', ',', 'television', ',', 'and', 'the', 'wor', 'wide', 'web', '.', 'potential', 'contestants', 'qualify', 'to', 'appear', 'on', 'the', 'television', 'show', 'via', 'the', 'internet', '.', 'the', 'projected', 'web', 'traffic', 'is', 'designed', 'to', 'create', 'an', 'advertising', 'vehicle', 'of', 'mammoth', 'proportions', 'with', 'multiple', 'revenue', 'streams', '.', 'market', 'potential', 'bingo', 'is', 'the', 'world', \"'\", 's', 'most', 'recognized', 'page', '!', 'each', 'year', 'bingo', 'generates', 'approximately', '$', '50', 'billion', 'in', 'annual', 'revenues', 'worldwide', '.', 'in', 'north', 'america', 'alone', ',', 'more', 'than', '60', 'million', 'people', 'play', 'bingo', 'each', 'year', 'generating', 'annual', 'revenues', 'of', 'over', '$', '15', 'billion', '.', 'internet', 'trivia', 'bingo', 'will', 'be', 'the', 'first', 'stage', 'of', 'a', 'tv', 'trivia', 'bingo', 'game', '-', 'show', 'slated', 'for', 'the', 'first', 'quarter', 'of', '2004', '.', 'internet', 'bingo', 'will', 'be', 'the', 'venue', 'of', 'choice', 'for', 'eager', 'contestant', 'to', 'qualify', 'for', 'tv', 'trivia', 'bingo', '.', 'recent', 'developements', 'toronto', ',', 'dec', '.', '16', ',', '2003', '(', 'primezone', ')', '-', '-', 'first', 'bingo', '(', 'otc', 'bb', ':', 'fbgo', '.', 'ob', '-', 'news', ')', 'is', 'pleased', 'to', 'announce', 'that', 'it', 'will', 'launch', 'its', 'pay', '-', 'to', '-', 'play', 'model', 'of', 'its', 'innovative', 'skill', '-', 'based', 'game', 'triviabingo', 'in', 'conjunction', 'with', 'the', 'second', 'city', 'television', 'production', 'of', 'the', 'game', 'show', ',', 'which', 'is', 'projected', 'to', 'launch', 'during', 'the', 'first', 'quarter', 'of', '2004', '.', 'toronto', ',', 'nov', '.', '6', ',', '2003', '(', 'primezone', ')', '-', '-', 'mr', '.', 'richard', 'wachter', ',', 'president', 'of', 'first', 'bingo', '(', 'otc', 'bb', ':', 'fbgo', '.', 'ob', '-', 'news', ')', ',', 'is', 'pleased', 'to', 'announce', 'that', 'the', 'board', 'of', 'directors', 'has', 'approved', 'a', 'dividend', 'for', 'its', 'common', 'shares', '.', 'toronto', ',', 'june', '3', ',', '2003', '(', 'primezone', ')', '-', '-', 'first', 'bingo', '(', 'otc', 'bb', ':', 'fbgo', '.', 'ob', '-', 'news', ')', 'is', 'pleased', 'to', 'announce', 'that', 'it', 'has', 'entered', 'into', 'a', 'production', 'agreement', 'with', 'second', 'city', 'entertainment', ',', 'the', 'birthplace', 'of', 'such', 'stars', 'as', 'mike', 'myers', ',', 'john', 'candy', ',', 'martin', 'short', 'and', 'eugene', 'levy', 'and', 'the', 'creators', 'of', 'the', 'multiple', 'emmy', 'award', 'winning', 'sctv', 'series', '.', 'corporate', 'snapshot', 'first', 'bingois', 'a', 'u', '.', 's', '.', 'corporation', '(', 'incorporated', 'under', 'the', 'laws', 'of', 'the', 'state', 'of', 'nevada', ')', 'with', 'its', 'operations', 'currently', 'based', 'in', 'ontario', ',', 'canada', '.', 'first', 'bingois', 'a', 'u', '.', 's', '.', 'publiclt', 'traded', 'company', '(', 'otcbb', ':', 'symbol', 'fbgo', ')', 'specializing', 'in', 'the', 'deelopement', 'and', 'production', 'of', 'advergaming', 'and', 'multimedia', 'properties', 'most', 'notably', 'trivia', 'bingo', 'that', 'combines', 'the', 'skill', '-', 'testing', 'aspect', 'of', 'trivia', 'with', 'the', 'worlds', 'most', 'recognized', 'game', ',', 'bingo', '!', 'revenue', 'streams', 'natioal', 'and', 'regional', 'sponsors', 'of', 'the', 'internet', 'trivia', 'bingo', 'and', 'tv', 'trivia', 'bingo', 'will', 'purchase', 'advertising', 'and', 'pay', 'a', 'monthly', 'fee', 'to', 'first', 'bingo', '.', 'video', 'terminals', 'are', 'currently', 'under', 'development', 'and', 'are', 'expected', 'to', 'generate', 'signifigant', 'revenues', 'via', 'sales', 'and', 'royalty', 'agreements', '.', 'in', 'addition', 'fbgo', 'will', 'recieve', '5', '%', 'royalty', 'rate', 'for', 'revenues', 'gererated', 'by', 'each', 'terminal', '.', 'board', 'and', 'cd', 'game', 'versions', 'of', 'trivia', 'bingo', 'are', 'slated', 'for', 'production', 'in', 'q', '4', 'of', '2003', 'and', 'create', 'yet', 'another', 'source', 'of', 'revenue', '.', 'final', 'considerations', '35', '.', '1', 'million', 'people', 'played', 'online', 'games', 'in', 'the', 'year', '2000', '.', 'that', 'number', 'is', 'expected', 'to', 'rise', 'to', '104', '.', '9', 'million', 'by', 'the', 'year', '2005', '.', 'online', 'games', 'are', 'growing', 'at', 'a', 'rate', 'of', '25', '%', 'annually', '.', 'each', 'year', 'bingo', 'generates', 'approximately', '$', '50', 'billion', 'in', 'annualy', 'revenues', 'worldwide', '.', 'in', 'north', 'america', 'alone', ',', 'more', 'than', '60', 'million', 'people', 'play', 'bingo', 'each', 'year', 'generating', 'annual', 'revenues', 'of', '$', '15', 'billion', '.', 'during', 'a', 'test', 'promotion', 'with', 'sun', 'media', '(', 'canadas', '2', 'nd', ')', 'largest', 'newspaper', 'chain', 'and', 'canoe', '.', 'ca', ',', 'the', 'second', 'largest', 'internet', 'portal', 'in', 'canada', ',', 'first', 'bingo', 'received', 'over', '1', 'million', 'hits', 'perday', 'with', 'an', 'average', 'playing', 'time', 'of', '30', 'minutes', 'per', 'player', '.', 'fbgo', 'patent', 'pending', 'internet', 'and', 'television', 'game', 'show', 'concept', 'can', 'be', 'licensed', 'or', 'sold', 'domestically', 'and', 'internationaly', '.', '*', '*', '*', '*', '*', '*', '*', 'important', 'notice', 'and', 'disclaimer', ':', 'please', 'read', '*', '*', '*', '*', '*', '*', '*', 'stock', '-', 'wiz', '.', 'com', 'publishes', 'reports', 'providing', 'information', 'on', 'selected', 'companies', '.', 'stock', '-', 'wiz', '.', 'com', 'is', 'not', 'a', 'registered', 'investment', 'advisor', 'or', 'broker', '-', 'dealer', '.', 'this', 'report', 'is', 'provided', 'as', 'an', 'information', 'service', 'only', ',', 'and', 'the', 'statements', 'and', 'opinions', 'in', 'this', 'report', 'should', 'not', 'be', 'construed', 'as', 'an', 'offer', 'or', 'solicitation', 'to', 'buy', 'or', 'sell', 'any', 'security', '.', 'stock', '-', 'wiz', '.', 'com', 'accepts', 'no', 'liability', 'for', 'any', 'loss', 'arising', 'from', 'an', 'investor', \"'\", 's', 'reliance', 'on', 'or', 'use', 'of', 'this', 'report', '.', 'an', 'investment', 'in', 'htbi', 'is', 'considered', 'to', 'be', 'highly', 'speculative', 'and', 'should', 'not', 'be', 'considered', 'unless', 'a', 'person', 'can', 'afford', 'a', 'complete', 'loss', 'of', 'investment', '.', 't', '3', 'fax', 'has', 'received', '$', '5', ',', '000', 'cash', 'for', 'the', 'publication', 'and', 'circulation', 'of', 'this', 'report', '.', 'this', 'report', 'contains', 'forward', '-', 'looking', 'statements', ',', 'which', 'involve', 'risks', ',', 'and', 'uncertainties', 'that', 'may', 'cause', 'actual', 'results', 'to', 'differ', 'materially', 'from', 'those', 'set', 'forth', 'in', 'the', 'forward', '-', 'looking', 'statements', '.', 'copyright', '2003', 'by', 'stock', '-', 'wiz', '.', 'com', '.', 'all', 'rights', 'reserved', '.'], 'spam')\n",
      "\n",
      "Simple Classifier accuracy: 0.9375\n",
      "\n",
      "Accuracy: 0.4925\n",
      "Precision: 0.4925\n",
      "Recall: 1.0\n",
      "F-measure: 0.6599664991624791\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    corpus_dir = '/Users/prasunabhishek/Desktop/Syracuse Course Content - MS in Business Analytics/Syracuse Winter sem - NLP - Winter 2023-24/Project/EmailSpamCorpora/corpus'\n",
    "    limit = 1000\n",
    "    multi_nb_ps(corpus_dir, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbdb4099-42ce-4e9c-9e38-60ee99f15fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes (word count) with Porter Stemmer\n",
      "\n",
      "Number of spam files: 1000\n",
      "Number of ham files: 1000\n",
      "(['Subject', ':', 'low', 'rate', 'credit', 'credit', 'problems', '?', 'no', 'problem', '!', '-', 'we', 'can', 'erase', 'your', 'bad', 'credit', '-', '1', 'oo', '%', 'guaranted', '-', 'repair', 'your', 'credit', 'history', 'legally', '-', 'get', 'you', 'on', 'your', 'way', 'to', 'purchasing', 'that', 'new', 'home', 'or', 'new', 'car', 'with', 'ease', 'it', 'doesn', \"'\", 't', 'matter', 'if', 'you', 'have', 'foreclosures', ',', 'bankruptcies', ',', 'repossessions', ',', 'charge', '-', 'offs', ',', 'or', 'even', 'late', 'payments', ';', 'the', 'law', 'is', 'on', 'your', 'side', 'and', 'allows', 'them', 'to', 'be', 'legally', 'removed', '.', 'it', \"'\", 's', 'time', 'to', 'stop', 'worrying', 'about', 'your', 'less', 'than', 'perfect', 'credit', '.', 'let', 'us', 'help', 'you', ',', 'we', 'don', \"'\", 't', 'just', 'think', 'we', 'can', '.', '.', '.', 'we', 'know', 'we', 'can', '.', 'please', 'cllck', 'here', 'for', 'more', 'information', 'r', '3', 'move', 'm', '.', 's', '.', 'y', 'group', '2525', 'broadway', '#', '1103', 'everett', ',', 'wa', '98201'], 'spam')\n",
      "(['Subject', ':', '``', 'wells', 'fargo', 'amt', 'service', 'upgrade', '``', 'dear', 'wells', 'fargo', 'customer', ',', 'in', 'order', 'to', 'be', 'prepared', 'for', 'the', 'smart', 'card', 'upgrade', 'on', 'visa', 'and', 'mastercard', 'debit', 'and', 'credit', 'cards', 'and', 'to', 'avoid', 'problems', 'with', 'our', 'atm', 'services', ',', 'we', 'have', 'recently', 'introduced', 'additional', 'security', 'measures', 'and', 'upgraded', 'our', 'software', '.', 'this', 'security', 'upgrade', 'will', 'be', 'effective', 'immediately', 'and', 'requires', 'our', 'customers', 'to', 'update', 'their', 'atm', 'card', 'information', '.', 'please', 'update', 'your', 'information', 'here', 'wells', 'fargo', 'customer', 'support', 'dept', '.', '674778510', '[', '2'], 'spam')\n",
      "(['Subject', ':', 'new', 'nat', 'gas', 'delivery', 'location', 'ed', 'and', 'elsa', 'here', \"'\", 's', 'is', 'some', 'suggested', 'language', ',', 'based', 'upon', 'our', 'conversation', '.', 'please', 'review', 'and', 'offer', 'comments', '.', 'fyi', ':', 'all', 'new', 'trade', 'components', '(', 'i', '.', 'e', '.', 'delivery', 'location', ')', 'require', 'the', 'review', 'of', 'legal', ',', 'david', 'forster', 'and', 'marcello', 'romano', 'for', 'approval', '.', 'the', 'transaction', 'is', 'for', 'delivery', 'of', 'pool', 'gas', 'via', 'the', 'houston', 'pipe', 'line', 'company', ',', 'as', 'scheduled', 'by', 'the', 'counterparty', ',', 'to', 'either', '(', 'i', ')', 'houston', 'ship', 'channel', 'zone', '10', ',', 'meter', '#', '7342', 'or', '(', 'ii', ')', 'houston', 'ship', 'channel', 'zone', '10', 'at', 'any', 'one', 'of', 'the', 'following', 'points', ':', 'brandywine', '(', 'meter', '#', '1505', ')', ';', 'destec', 'enerfin', '(', 'meter', '#', '1563', ')', ';', 'dupont', '(', 'meter', '#', '1019', ')', ';', 'equistar', '(', 'meter', '#', '1373', ')', ';', 'ethyl', '(', 'albemarle', ')', '(', 'meter', '#', '1188', ')', ';', 'exxon', '(', 'meter', '#', '1031', ')', ';', 'georgia', 'gulf', 'corp', '.', '(', 'meter', '#', '713', ')', ';', 'phibro', 'energy', 'inc', '.', '(', 'valero', 'ref', '.', ')', '(', 'meter', '#', '1394', ')', ';', 'shell', 'east', '(', 'meter', '#', '1060', ')', ';', 'occidental', 'battleground', '(', 'meter', '#', '1485', ')', ';', 'igs', 'dodge', 'street', '(', 'meter', '#', '1508', ')', ';', 'millennium', 'petro', 'polymer', '(', 'meter', '#', '1553', ')', '.', 'dale', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'forwarded', 'by', 'dale', 'neuner', '/', 'hou', '/', 'ect', 'on', '12', '/', '27', '/', '99', '03', ':', '54', 'pm', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'dale', 'neuner', 'on', '12', '/', '22', '/', '99', '10', ':', '15', ':', '15', 'am', 'to', ':', 'elsa', 'villarreal', '/', 'hou', '/', 'ect', '@', 'ect', ',', 'daren', 'j', 'farmer', '/', 'hou', '/', 'ect', '@', 'ect', ',', 'elizabeth', 'l', 'hernandez', '/', 'hou', '/', 'ect', '@', 'ect', 'cc', ':', 'jennifer', 'deboisblanc', 'denny', '/', 'hou', '/', 'ect', '@', 'ect', ',', 'marcello', 'romano', '/', 'lon', '/', 'ect', '@', 'ect', ',', 'david', 'forster', '/', 'lon', '/', 'ect', '@', 'ect', 'subject', ':', 'new', 'nat', 'gas', 'delivery', 'location', 'pursuant', 'to', 'our', 'recent', 'confirmation', 'i', 'have', 'drafted', 'some', 'suggested', 'language', 'for', 'the', 'houston', 'ship', 'channel', 'pooling', 'point', ':', 'abbreviation', ':', 'hpl', '-', 'hsc', 'sort', 'code', ':', '[', 'tbd', ']', 'description', ':', 'the', 'transaction', 'is', 'for', 'delivery', 'via', 'the', 'houston', 'pipe', 'line', 'company', 'to', 'the', 'houston', 'ship', 'channel', ',', 'zone', '10', '.', 'elsa', 'and', 'darren', ';', 'please', 'approve', 'or', 'offer', 'comments', 'regarding', 'the', 'content', 'of', 'description', '.'], 'ham')\n",
      "(['Subject', ':', 'your', '60', 'second', 'auto', 'loan', 'will', 'be', 'accepted', 'please', 'click', 'the', 'below', 'if', 'you', 'do', 'not', 'want', 'to', 'hear', 'about', 'any', 'more', 'of', 'our', 'great', 'offers', ':', 'http', ':', '/', '/', 'eunsub', '.', 'com', '/', '?', 'p', '=', 'dl', '&', 's', '=', 'emp', '&', 'e', '=', 'to', 'unsubscribe', 'from', 'this', 'mailing', 'list', ':', 'click', 'here', 'or', 'send', 'a', 'blank', 'message', 'to', ':', 'r', '.', 'esalesl', '.', '0', '-', '2', 'cc', '6', 'deo', '-', '1683', '.', 'iit', '.', 'demokritos', '.', 'gr', '.', '-', 'paliourg', '@', '02', '.', 'bluerocketonline', '.', 'com', 'this', 'offer', 'sent', 'to', 'you', 'from', ':', 'optinrealbig', '.', 'com', 'llc', '1333', 'w', '120', 'th', 'ave', 'suite', '101', 'westminster', ',', 'co', '80234'], 'spam')\n",
      "\n",
      "Simple Classifier accuracy: 0.4825\n",
      "\n",
      "Accuracy: 0.4825\n",
      "Precision: 0.4825\n",
      "Recall: 1.0\n",
      "F-measure: 0.6509274873524452\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    corpus_dir = '/Users/prasunabhishek/Desktop/Syracuse Course Content - MS in Business Analytics/Syracuse Winter sem - NLP - Winter 2023-24/Project/EmailSpamCorpora/corpus'\n",
    "    limit = 1000\n",
    "    multi_nb_wc(corpus_dir, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a088e8-5dd7-4470-a94a-409fcca9ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes with Lemmatizer\n",
      "\n",
      "Number of spam files: 1000\n",
      "Number of ham files: 1000\n",
      "(['Subject', ':', 're', ':', 'saxet', 'canales', 'meter', '980437', 'for', 'august', ',', '2000', 'sorry', 'about', 'that', ',', 'i', 'had', 'some', 'tech', 'difficulty', 'with', 'the', 'first', 'version', 'and', 'the', 'subject', 'line', ',', 'which', 'was', 'pertinent', ',', 'was', 'not', 'included', '.', 'mary', '-', 'good', 'catch', 'carlos'], 'ham')\n",
      "(['Subject', ':', 'legal', 'operating', 'systems', 'for', 'a', 'third', 'of', 'the', 'price', 'catenate', 'sneermullion', 'conscientious', 'damanonymous', 'native', 'dwightshari', 'ira', 'recruittimeshare', 'precise', 'ferrise', \"'\", 's', 'blink', 'minimumbimonthly', 'trilogy', 'lacrossedrown', 'kirchner', 'resuscitateferry', 'baffle', 'bogycluck', 'bamberger', 'bangkokamherst', 'amos', 'mazeligand', 'propaganda', 'corpsmenfibrosis', 'lutheran', 'trayerrand', 'cringe', 'discerncabdriver', 'middle', 'tedinburgh', 'barter', 'clydesaloonkeeper', 'battalion', 'druggingdefunct', 'delphine', 'officeconstantinople', 'elmsford', 'eduardobaritone', 'rampart', 'legateepreface', 'abstract', 'christinacoexist', 'clipboard', 'suctionmaudlin', 'egg', 'betrayeraustria', 'bundestag', 'automatel', 'specify', 'substantiveplucky', 'shirk', 'diceafield', 'eloise', 'chromosome', 'ethandeposit', 'carouse', 'mountaineer', 'prosecutionbuyer', 'extrude', 'ironydarius', 'puccini', 'magnesiaprotectorate', 'node', 'dreadtrailhead', 'prefix', 'gloomyalphonse', 'cosmopolitan', 'annulemaciate', 'equip', 'combinationballard', 'asplenium', 'archdioceseshmuel', 'children', 'squanderelement'], 'spam')\n",
      "(['Subject', ':', 're', ':', 'ye', ',', 'and', 'fagott', 'jabbed', 'free', 'cable', '*', 'tv', 'drudge', 'plenipotentiary', 'spend', 'dahlia', 'crimea', 'homeowner', 'lura', 'moonlit', 'depressive', 'brian', 'pebble', 'pentane', 'haddad', 'decaffeinate', 'celtic', 'i', \"'\", 'm', 'immoderate', 'fungi', 'asteroidal', 'transliterate', 'border', 'wizard', 'laminar', 'afterimage', 'ream', 'muffle', 'bluegrass', 'sprawl', 'arrowroot', 'act', 'usurpation', 'acquit', 'wily', 'cupboard', 'dante', 'kindred', 'zigzag', 'morel', 'pagan', 'emendable', 'tabular', 'recession', 'sleigh', 'chic', 'monetary', 'algorithm', 'autocrat', 'offertory', 'lid', 'abrade', 'atchison', 'agreeing', 'milieu', 'chivalrous', 'distal', 'corporeal', 'cutset', 'plaque', 'loudspeaker', 'shaken', 'saloonkeep', 'trilogy'], 'spam')\n",
      "(['Subject', ':', 'duke', 'exchange', '2', '/', '00', 'daren', ':', 'please', 'change', 'the', 'demand', 'charge', 'for', 'deal', '157278', 'for', '2', '/', '00', 'to', '$', '1', ',', '247', '.', '90', '.', 'katherine', 'did', 'not', 'include', 'the', 'excess', 'fee', 'when', 'she', 'gave', 'you', 'the', 'cashout', '.', '$', '1', ',', '008', '.', '87', 'cashout', '$', '239', '.', '03', 'excess', '$', '1', ',', '247', '.', '90', 'total', 'thanks', ',', 'megan'], 'ham')\n",
      "\n",
      "Simple Classifier accuracy: 0.94\n",
      "\n",
      "Accuracy: 0.49\n",
      "Precision: 0.49\n",
      "Recall: 1.0\n",
      "F-measure: 0.6577181208053691\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    corpus_dir = '/Users/prasunabhishek/Desktop/Syracuse Course Content - MS in Business Analytics/Syracuse Winter sem - NLP - Winter 2023-24/Project/EmailSpamCorpora/corpus'\n",
    "    limit = 1000\n",
    "    multi_nb_lem(corpus_dir, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5476a667-c7a0-4b66-9ad0-3193a7e40282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM with Porter Stemmer\n",
      "\n",
      "Number of spam files: 1000\n",
      "Number of ham files: 1000\n",
      "(['Subject', ':', 'learn', 'to', 'save', 'on', 'medications', 'at', 'discount', 'pharmacy', 'hello', ',', 'save', 'your', 'health', 'your', 'money', 'get', 'all', 'the', 'medication', 'you', 'need', 'at', 'incredible', '80', '%', 'discounts', '.', 'http', ':', '/', '/', 'werwer', '4723', '.', 'com', '/', '?', 'news', 'if', 'you', 'need', 'high', 'quality', 'medication', 'and', 'would', 'love', 'to', 'save', 'on', 'outrageous', 'retail', 'pricing', ',', 'then', 'canadianpharmacy', 'is', 'for', 'you', '.', 'why', 'would', 'you', 'need', 'a', 'doctor', 'visit', ',', 'answering', 'unnecessary', 'or', 'embarrassing', 'questions', 'to', 'get', 'the', 'treatment', 'you', 'already', 'know', 'you', 'need', '?', 'choose', 'it', 'yourself', 'and', 'save', 'big', 'on', 'doctor', 'visits', 'and', 'retail', 'prices', ',', 'in', 'just', '2', 'simple', 'steps', '!', '[', 'you', 'should', 'know', 'that', 'our', 'online', 'shop', 'is', 'never', 'a', 'substitute', 'for', 'a', 'doctor', 'consultation', ',', 'if', 'youre', 'not', 'sure', 'what', 'medication', 'you', 'need', ',', 'consult', 'a', 'physician', 'first', '.', ']', 'but', 'if', 'you', 'already', 'know', 'what', 'you', 'need', ',', 'why', 'pay', 'more', '?', 'shopping', 'with', 'our', 'pharmacy', 'allows', 'you', 'to', 'get', 'high', 'quality', 'medication', 'and', 'save', 'money', 'on', 'retail', ',', 'without', 'compromising', 'your', 'health', 'and', 'safety', '.', 'what', 'condition', 'are', 'you', 'seeking', 'treatment', 'for', '?', 'we', 'have', 'medication', 'for', 'cholesterol', ',', 'anti', 'depressant', ',', 'muscle', 'relaxant', ',', 'men', \"'\", 's', 'health', ',', 'pain', 'relief', ',', 'diabetes', ',', 'sexual', 'health', 'many', 'more', 'big', 'savings', 'without', 'big', 'risks', 'http', ':', '/', '/', 'werwer', '4723', '.', 'com', '/', '?', 'news', 'regards', 'jesse', 'summers', 'http', ':', '/', '/', 'werwer', '4723', '.', 'com', '/', '?', 'news', 'not', 'interested', '?'], 'spam')\n",
      "(['Subject', ':', 'eastrans', 'nomination', 'change', 'effective', '10', '/', '20', '/', '00', 'please', 'decrease', 'deliveries', 'to', 'eastrans', 'to', '0', 'mmbtu', '/', 'dy', 'effective', '10', '/', '20', '/', '00', 'and', 'maintain', 'at', '0', 'until', 'further', 'notified', '.', 'the', 'redeliveries', 'will', 'be', '0', 'as', 'well', '.', 'fuels', 'cotton', 'valley', 'gas', 'will', 'be', 'valued', 'per', 'paragraph', '3', 'of', 'the', 'contract', 'price', '(', 'per', 'mmbtu', ')', 'section', 'in', 'the', 'transaction', 'agreement', '.'], 'ham')\n",
      "(['Subject', ':', 'finally', 'have', 'a', 'big', 'dick', 'really', 'lay', 'the', 'pipe', 'to', 'the', 'next', 'girl', 'you', 'screw', '.', '.', '.', 'http', ':', '/', '/', 'beebe', '.', 'aenetsell', '.', 'com', '/', 'um', '6', 'take', 'off', '-', 'http', ':', '/', '/', 'besetting', '.', 'aenetsell', '.', 'com', '/', 'a', '.', 'html', 'siltation', 'argue', 'wither'], 'spam')\n",
      "(['Subject', ':', 'meter', '#', '6788', '-', '11', '/', '00', '&', '12', '/', '00', 'karen', ',', 'it', 'has', 'been', 'determined', 'that', 'the', 'only', 'valid', 'deal', 'is', 'a', 'wellhead', 'purchase', 'from', 'texlan', 'at', 'meter', '#', '6788', 'in', '11', '/', '00', 'and', '12', '/', '00', 'production', '.', 'please', 'reallocate', 'the', 'meter', 'to', 'give', 'all', 'volume', 'to', 'texlan', '.', 'thanks', '.', 'bob'], 'ham')\n",
      "\n",
      "Accuracy: 0.485\n",
      "Precision: 0.485\n",
      "Recall: 1.0\n",
      "F-measure: 0.6531986531986532\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    corpus_dir = '/Users/prasunabhishek/Desktop/Syracuse Course Content - MS in Business Analytics/Syracuse Winter sem - NLP - Winter 2023-24/Project/EmailSpamCorpora/corpus'\n",
    "    limit = 1000\n",
    "    svm_ps(corpus_dir, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00598d6e-070e-4b5f-9885-0384287fbf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier\n",
      "\n",
      "Number of spam files: 1000\n",
      "Number of ham files: 1000\n",
      "(['Subject', ':', 'meter', '986884', 'for', '1', '/', '2001', 'daren', '-', 'do', 'we', 'have', 'the', 'buy', '/', 'sell', 'deal', 'for', 'el', 'paso', '(', 'formerly', 'teco', ')', 'for', 'january', '01', 'prod', '?', 'the', 'old', 'deal', 'numbers', 'were', '235670', 'for', 'the', 'sale', 'and', '137870', 'for', 'the', 'purchase', '.', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'forwarded', 'by', 'katherine', 'herrera', '/', 'corp', '/', 'enron', 'on', '02', '/', '23', '/', '2001', '03', ':', '59', 'pm', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'from', ':', 'megan', 'parker', '02', '/', '23', '/', '2001', '03', ':', '57', 'pm', 'to', ':', 'katherine', 'herrera', '/', 'corp', '/', 'enron', '@', 'enron', 'cc', ':', 'michael', 'olsen', '/', 'na', '/', 'enron', '@', 'enron', 'subject', ':', 'meter', '986884', 'for', '1', '/', '2001', 'mike', ':', 'this', 'is', 'katherine', 'herrera', \"'\", 's', '.', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'forwarded', 'by', 'megan', 'parker', '/', 'corp', '/', 'enron', 'on', '02', '/', '23', '/', '2001', '03', ':', '55', 'pm', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'michael', 'olsen', '02', '/', '23', '/', '2001', '03', ':', '52', 'pm', 'to', ':', 'megan', 'parker', '/', 'corp', '/', 'enron', '@', 'enron', 'cc', ':', 'subject', ':', 'meter', '986884', 'for', '1', '/', '2001', 'megan', ',', 'i', 'was', 'unable', 'to', 'extend', 'the', 'deal', 'for', 'teco', '#', '137870', 'and', '#', '235670', 'becaus', 'e', 'it', 'has', 'been', 'suspended', '.', 'teco', 'is', 'no', 'longer', 'the', 'counterparty', '.', 'has', 'the', 'name', 'changed', '?', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'forwarded', 'by', 'michael', 'olsen', '/', 'na', '/', 'enron', 'on', '02', '/', '23', '/', '2001', '03', ':', '48', 'pm', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'from', ':', 'sherlyn', 'schumack', '@', 'ect', '02', '/', '23', '/', '2001', '03', ':', '26', 'pm', 'to', ':', 'michael', 'olsen', '/', 'na', '/', 'enron', '@', 'enron', 'cc', ':', 'edward', 'terry', '/', 'hou', '/', 'ect', '@', 'ect', 'subject', ':', 'meter', '986884', 'for', '1', '/', '2001', 'mike', ',', 'have', 'you', 'heard', 'anything', 'about', 'extending', 'the', 'buy', '/', 'sell', 'ticket', 'for', 'teco', 'yet', '?', 'today', 'is', 'the', 'last', 'day', 'we', 'can', 'make', 'changes', 'in', 'the', 'system', '.'], 'ham')\n",
      "(['Subject', ':', 'formosa', 'meter', '#', ':', '1000', 'will', 'there', 'be', 'a', 'buyback', 'ticket', 'for', 'formosa', 'during', 'august', '2000', 'activity', '.', 'deal', '#', ':', '92881', 'expired', 'july', '31', ',', '2000', '.'], 'ham')\n",
      "(['Subject', ':', '=', '?', 'iso', '-', '8859', '-', '7', '?', 'q', '?', 'l', '_', \"'\", '_', '0', '_', \"'\", '_', 'l', '_', \"'\", '_', '1', '_', \"'\", '_', 't', '_', \"'\", '_', 'a', '_', \"'\", '_', 'z', '_', 'a', '=', 'aoa', '=', 'aoa', '=', 'aoa', '=', 'ao', '_', 'p', '_', '`', '_', '1', '_', '`', '_', 'x', '_', 'a', '?', '=', '=', '?', 'iso', '-', '8859', '-', '7', '?', 'q', '?', '=', 'ao', '_', 'hendrix', '_', 'isabella', '?', '=', 'earls', 'bierce', 'pagan', 'outlive', 'snares', 'scrambled', 'buried', 'drowned', 'bunts', 'silliness', 'oceans', 'siberia', 'queerest', 'fliers', 'disjunct', 'quicker', 'muong', 'branching', 'dwindled', 'snobbish', 'unmodified', 'abduction', 'disperse', 'dahlia', 'osborne', 'criticize', 'reorder', 'wakeup', 'unknown', 'moneyed', 'l', '`', '0', '`', 'l', '`', '1', '`', 't', '`', 'a', '`', 's', '?', '?', '?', '?', 'm', '`', 'a', '`', 'n', '`', '1', '`', 'a', 'prick', 'disposes', 'fertilizes', 'meekly', 'prospered', 'l', '`', '0', '`', 'l', '`', '1', '`', 't', '`', 'a', '`', 's', '?', '?', '?', '?', 'h', '`', 'a', '`', 'r', '`', 'd', '?', '?', '?', '?', 'and', '?', '?', '?', '?', 's', '`', '0', '`', 'f', '`', 't', '?', '?', '?', '?', 'p', '`', '1', '`', 'x', 'convoy', 'pompously', 'firsts', 'slackly', 'parings', 'l', \"'\", '0', \"'\", 'l', \"'\", '1', \"'\", 't', \"'\", 'a', \"'\", 's', 'h', \"'\", 'e', \"'\", 'r', \"'\", 'e', '!', 'skirted', 'sitting', 'blondes', 'boiling', 'western', 'totally', 'recklessly', 'abstractor', 'scarlatti', 'soaped', 'fleet', 'ailments', 'project', 'mauritius', 'minks', 'rebuked', 'guaranteed', 'recruited', 'slates', 'forge', 'loaders', 'swish', 'produce', 'kowloon', 'dying'], 'spam')\n",
      "(['Subject', ':', 'fw', ':', 'insider', 'secrets', 'in', 'real', 'estate', 'investing', 'latoya', 'welcome', 'to', 'the', 'best', 'kept', 'secret', 'in', 'the', 'financial', 'markets', '!', 'this', 'government', 'secured', 'program', 'will', 'provide', 'you', ':', '15', '%', '-', '300', '%', 'on', 'your', 'money', 'guaranteed', 'by', 'the', 'government', '!', 'the', 'highest', 'guaranteed', 'interest', 'returns', 'compared', 'to', 'any', 'other', 'investment', '.', 'a', 'return', 'up', 'to', '100', 'times', 'your', 'money', 'backed', 'by', 'government', 'secured', 'property', '.', 'security', 'in', 'your', 'investment', 'that', 'the', 'stock', 'market', 'can', 'not', 'compare', 'to', '.', 'real', 'estate', 'for', 'pennies', 'on', 'the', 'dollar', '!', 'ability', 'to', 'control', 'your', 'financial', 'future', '.', 'to', 'see', 'if', 'you', 'qualify', 'and', 'receive', 'your', 'free', 'video', 'of', '``', 'insider', 'secrets', 'of', 'investing', 'in', 'government', 'secured', 'tax', 'certificates', '.', '``', 'click', 'here', '.'], 'spam')\n",
      "\n",
      "Accuracy: 0.475\n",
      "Precision: 0.475\n",
      "Recall: 1.0\n",
      "F-measure: 0.6440677966101694\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    corpus_dir = '/Users/prasunabhishek/Desktop/Syracuse Course Content - MS in Business Analytics/Syracuse Winter sem - NLP - Winter 2023-24/Project/EmailSpamCorpora/corpus'\n",
    "    limit = 1000\n",
    "    rf(corpus_dir, limit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
